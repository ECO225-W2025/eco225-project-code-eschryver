{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Code for Emerson's Homeownership Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipumspy.readers as readers # For census data (retrived from IPUMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"enterprise_flag\",\n",
    "    \"record_number\",\n",
    "    \"state_fips\",\n",
    "    \"msa_code\",\n",
    "    \"county_fips\",\n",
    "    \"census_tract\",\n",
    "    \"tract_pct_minority\",\n",
    "    \"tract_median_income\",\n",
    "    \"local_median_income\",\n",
    "    \"tract_income_ratio\",\n",
    "    \"borrower_income\",\n",
    "    \"area_median_income\",\n",
    "    \"borrower_income_ratio\",\n",
    "    \"upb_acquisition\",\n",
    "    \"purpose\",\n",
    "    \"fed_guarantee\",\n",
    "    \"num_borrowers\",\n",
    "    \"first_time_homebuyer\",\n",
    "    \"borrower_race\",\n",
    "    \"borrower_ethnicity\",\n",
    "    \"coborrower_race\",\n",
    "    \"coborrower_ethnicity\",\n",
    "    \"borrower_gender\",\n",
    "    \"coborrower_gender\",\n",
    "    \"borrwer_age\",\n",
    "    \"coborrower_age\",\n",
    "    \"occupancy_code\",\n",
    "    \"rate_spread\",\n",
    "    \"hoepa_status\",\n",
    "    \"property_type\",\n",
    "    \"lien_status\",\n",
    "    \"borrower_over_62\",\n",
    "    \"co_borrower_over_62\",\n",
    "    \"ltv\",\n",
    "    \"date_of_note\",\n",
    "    \"term_at_org\",\n",
    "    \"num_of_units\",\n",
    "    \"interest_rate_at_org\",\n",
    "    \"note_amount\",\n",
    "    \"preapproval\",\n",
    "    \"application_channel\",\n",
    "    \"aus_name\",\n",
    "    \"borrower_credit_score_model\",\n",
    "    \"coborrower_credit_score_model\",\n",
    "    \"dti_ratio\",\n",
    "    \"discount_pts\",\n",
    "    \"intro_period\",\n",
    "    \"land_prop_interest\",\n",
    "    \"property_value\",\n",
    "    \"rural_tract\",\n",
    "    \"lower_ms_delta\",\n",
    "    \"middle_appalachia\",\n",
    "    \"persistent_poverty\",\n",
    "    \"concentrated_poverty\",\n",
    "    \"high_opportunity\",\n",
    "    \"qoz_tract\",\n",
    "]\n",
    "dropcols = [\n",
    "    \"enterprise_flag\",\n",
    "    \"record_number\",\n",
    "    \"borrower_income\",\n",
    "    \"upb_acquisition\",\n",
    "    \"purpose\",\n",
    "    \"fed_guarantee\",\n",
    "    \"rate_spread\",\n",
    "    \"hoepa_status\",\n",
    "    \"property_type\",\n",
    "    \"lien_status\",\n",
    "    \"borrower_over_62\",\n",
    "    \"co_borrower_over_62\",\n",
    "    \"ltv\",\n",
    "    \"term_at_org\",\n",
    "    \"num_of_units\",\n",
    "    \"interest_rate_at_org\",\n",
    "    \"preapproval\",\n",
    "    \"application_channel\",\n",
    "    \"aus_name\",\n",
    "    \"borrower_credit_score_model\",\n",
    "    \"coborrower_credit_score_model\",\n",
    "    \"discount_pts\",\n",
    "    \"intro_period\",\n",
    "    \"land_prop_interest\",\n",
    "    \"rural_tract\",\n",
    "    \"lower_ms_delta\",\n",
    "    \"middle_appalachia\",\n",
    "    \"persistent_poverty\",\n",
    "    \"concentrated_poverty\",\n",
    "    \"high_opportunity\",\n",
    "    \"qoz_tract\",\n",
    "]\n",
    "cols_pre2018 = [\n",
    "    \"enterprise_flag\",\n",
    "    \"record_number\",\n",
    "    \"state_fips\",\n",
    "    \"msa_code\",\n",
    "    \"county_fips\",\n",
    "    \"census_tract\",\n",
    "    \"tract_pct_minority\",\n",
    "    \"tract_median_income\",\n",
    "    \"local_median_income\",\n",
    "    \"tract_income_ratio\",\n",
    "    \"borrower_income\",\n",
    "    \"area_median_income\",\n",
    "    \"borrower_income_ratio\",\n",
    "    \"upb_acquisition\",\n",
    "    \"purpose\",\n",
    "    \"fed_guarantee\",\n",
    "    \"num_borrowers\",\n",
    "    \"first_time_homebuyer\",\n",
    "    \"borrower_race\",\n",
    "    \"borrower_ethnicity\",\n",
    "    \"coborrower_race\",\n",
    "    \"coborrower_ethnicity\",\n",
    "    \"borrower_gender\",\n",
    "    \"coborrower_gender\",\n",
    "    \"borrwer_age\",\n",
    "    \"coborrower_age\",\n",
    "    \"occupancy_code\",\n",
    "    \"rate_spread\",\n",
    "    \"hoepa_status\",\n",
    "    \"property_type\",\n",
    "    \"lien_status\",\n",
    "]\n",
    "dropcols_pre2018 = [\n",
    "    \"enterprise_flag\",\n",
    "    \"record_number\",\n",
    "    \"borrower_income\",\n",
    "    \"upb_acquisition\",\n",
    "    \"purpose\",\n",
    "    \"fed_guarantee\",\n",
    "    \"rate_spread\",\n",
    "    \"hoepa_status\",\n",
    "    \"property_type\",\n",
    "    \"lien_status\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/columns.txt\", \"w\") as f:\n",
    "    f.write(\"cols = \" + str(cols) + \"\\n\")\n",
    "    f.write(\"dropcols = \" + str(dropcols) + \"\\n\")\n",
    "    f.write(\"cols_pre2018 = \" + str(cols_pre2018) + \"\\n\")\n",
    "    f.write(\"dropcols_pre2018 = \" + str(dropcols_pre2018) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we want to have some dictionaries to decode data. For example, in the `loans` dataframe, each metropolitan area is given by its \"MSA code\", which means nothing to us. Rather, we want to know the MSA name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_codes = pd.read_csv('data/MSA_2023.txt', sep='\\s+=\\s+', header=None, engine='python', names=['msa_code', 'msa_name'])\n",
    "loans = loans.merge(msa_codes, on='msa_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start loading in data. Below is the code to load in the data from all years. This takes approximately 26 and a half minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_list = []\n",
    "\n",
    "# Loans from 2018-2023 (new system)\n",
    "for year in range(2018, 2023):\n",
    "    files = [f\"data/sf/fhlmc_sf{year}c_loans.txt\", f\"data/sf/fnma_sf{year}c_loans.txt\"]\n",
    "    loans_year = pd.concat(\n",
    "        [pd.read_csv(file, sep=r\"\\s+\", header=None, names=cols).drop(columns=dropcols) for file in files],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    loans_year[\"year\"] = year\n",
    "    loans_list.append(loans_year)\n",
    "    print(f\"Processed {year}\")\n",
    "print(\"First data done.\")\n",
    "\n",
    "# Loans from 2008-2017 (old system)\n",
    "for year in range(2008, 2018):\n",
    "    files = [f\"data/sf/fhlmc_sf{year}c_loans.txt\", f\"data/sf/fnma_sf{year}c_loans.txt\"]\n",
    "    loans_year = pd.concat(\n",
    "        [pd.read_csv(file, sep=r\"\\s+\", header=None, names=cols_pre2018).drop(columns=dropcols_pre2018) for file in files],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    loans_year[\"year\"] = year\n",
    "    loans_list.append(loans_year)\n",
    "    print(f\"Processed {year}\")\n",
    "\n",
    "loans = pd.concat(loans_list, ignore_index=True)\n",
    "\n",
    "# Saving\n",
    "loans.to_parquet(\"data/loans_data.parquet\", index=False)  \n",
    "\n",
    "print(\"Data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loans = pd.read_parquet(\"data/loans_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the data where mmi_per_thousand is greater than 20\n",
    "# filtered_data_high_mmi = filtered_data[filtered_data['mmi_per_thousand'] > 20]\n",
    "\n",
    "# # Plot the histogram of value_change\n",
    "# plt.hist(filtered_data_high_mmi['value_change'], bins=30, edgecolor='black')\n",
    "# plt.xlabel('Value Change')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of Value Change for MMI per Thousand > 20')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_data = data_table[(data_table['mmi_per_thousand'].abs() < 100)]\n",
    "# plt.scatter(filtered_data['mmi_per_thousand'], filtered_data['change_from_metro'])\n",
    "# plt.xlabel('Minority Move-ins per Thousand Whites in Zip Code')\n",
    "# plt.ylabel('Home Value Change (%) - Difference from MSA Average')\n",
    "# plt.title('Home Value Change and Minority Move-ins')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the quintiles for minority_move_ins\n",
    "# merged_quite_white_zhvi['quintile'] = pd.qcut(merged_quite_white_zhvi['minority_move_ins'], 5, labels=False)\n",
    "\n",
    "# # Group by quintile and calculate the average home appreciation\n",
    "# quintile_avg_appreciation = merged_quite_white_zhvi.groupby('quintile')['value_change'].mean().reset_index()\n",
    "\n",
    "# # Plot the bar chart\n",
    "# plt.bar(quintile_avg_appreciation['quintile'], quintile_avg_appreciation['value_change'])\n",
    "# plt.xlabel('Minority Move-in Quintile')\n",
    "# plt.ylabel('Average Home Appreciation (%)')\n",
    "# plt.title('Average Home Appreciation by Minority Move-in Quintile')\n",
    "# plt.xticks(quintile_avg_appreciation['quintile'], ['Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = data_table.dropna(subset=['change_in_min_share', 'value_diff_2019', 'msa_avg_value_ratio_2019', 'pct_rep', 'late_move_ins', 'per_cap_inc', 'white'])\n",
    "reg_data['rep_x_early_late'] = reg_data['pct_rep'] * reg_data['change_in_min_share']\n",
    "reg_data['highly_rep'] = (reg_data['pct_rep'] > reg_data['pct_rep'].quantile(0.50)).astype(int)\n",
    "reg_data['high_rep_x_chg'] = reg_data['highly_rep'] * reg_data['change_in_min_share']\n",
    "reg_data['intercept'] = 1\n",
    "X7 = reg_data[['intercept', 'change_in_min_share', 'pct_rep', 'msa_avg_value_ratio_2019', 'late_move_ins', 'per_cap_inc', 'white']]\n",
    "X8 = reg_data[['intercept', 'change_in_min_share', 'rep_x_early_late', 'msa_avg_value_ratio_2019', 'pct_rep', 'late_move_ins', 'per_cap_inc', 'white']]\n",
    "X9 = reg_data[['intercept', 'change_in_min_share', 'high_rep_x_chg', 'msa_avg_value_ratio_2019', 'highly_rep', 'late_move_ins', 'per_cap_inc', 'white']]\n",
    "y = reg_data['value_ratio_2019']\n",
    "model7 = sm.OLS(y, X7).fit()\n",
    "model8 = sm.OLS(y, X8).fit()\n",
    "model9 = sm.OLS(y, X9).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stargazer = Stargazer([model7, model8, model9])\n",
    "stargazer.custom_columns([\"Home Value Change (%) (2010-2017)\"],[3])\n",
    "HTML(stargazer.render_html())\n",
    "# print(stargazer.render_latex()) #if you use Latex (Overleaf.com)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
